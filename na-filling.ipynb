{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NA Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency, mode\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Airbnb_Data.csv'\n",
    "original_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing or invalid values:\n",
      "bathrooms: Missing or Null\n",
      "first_review: Missing or Null\n",
      "host_has_profile_pic: Missing or Null\n",
      "host_identity_verified: Missing or Null\n",
      "host_response_rate: Missing or Null\n",
      "host_since: Missing or Null\n",
      "last_review: Missing or Null\n",
      "neighbourhood: Missing or Null\n",
      "review_scores_rating: Missing or Null\n",
      "thumbnail_url: Missing or Null\n",
      "zipcode: Missing or Null\n",
      "bedrooms: Missing or Null\n",
      "beds: Missing or Null\n"
     ]
    }
   ],
   "source": [
    "# Which columns are NA / Null / INF / None/ 0\n",
    "\n",
    "df = original_df.copy()\n",
    "\n",
    "missing_values = ['NA', 'NaN', 'nan', 'Null', 'INF', '-INF', 'None', 0, '']\n",
    "\n",
    "# Initialize a dictionary to store columns with missing or invalid values\n",
    "columns_with_issues = {}\n",
    "\n",
    "# Check for missing or invalid values in each column\n",
    "for column in df.columns:\n",
    "    # Check for NaN, Null, and None values\n",
    "    if df[column].isna().any() or df[column].isnull().any() or df[column].eq(None).any():\n",
    "        columns_with_issues[column] = 'Missing or Null'\n",
    "    # Check for INF and -INF values\n",
    "    elif (df[column] == np.inf).any() or (df[column] == -np.inf).any():\n",
    "        columns_with_issues[column] = 'INF or -INF'\n",
    "    # Check for specific representations (e.g., 'NA', 'Null', 'None', 0)\n",
    "    elif df[column].astype(str).isin(missing_values).any():\n",
    "        columns_with_issues[column] = 'Specific Representation'\n",
    "\n",
    "# Print columns with missing or invalid values\n",
    "print(\"Columns with missing or invalid values:\")\n",
    "for column, issue in columns_with_issues.items():\n",
    "    print(f\"{column}: {issue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Column Analysis\n",
    "- Is it MCAR?\n",
    "- Is it MAR? missing because of other variables\n",
    "- IS it MNAR? missing because of that column\n",
    "\n",
    "\n",
    "- MCAR/MAR -> If categorical, use logistic reg/multiple imput. If continuous, use linear reg/multiple imput. Assuming they are better than using mean/median/mode\n",
    "Can consider KNN/Random Forest\n",
    "\n",
    "\n",
    "Ignore thumbnail_url\n",
    "\n",
    "\n",
    "- chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['property_type', 'room_type', 'accommodates', 'bathrooms', 'bed_type', 'cancellation_policy', 'cleaning_fee', 'city', 'first_review', 'host_has_profile_pic', 'host_identity_verified', 'host_response_rate', 'host_since', 'instant_bookable', 'last_review', 'latitude', 'longitude', 'neighbourhood', 'number_of_reviews', 'review_scores_rating', 'bedrooms', 'beds']\n"
     ]
    }
   ],
   "source": [
    "IGNORE_COLUMNS = [\"id\", \"log_price\", \"amenities\", \"name\", \"thumbnail_url\", \"description\", \"zipcode\"]\n",
    "COLUMNS_TO_CHECK_CORRELATION = list(original_df.columns)\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'cleaning_fee', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
    "DATE_COLUMNS = ['first_review', 'host_since', 'last_review']\n",
    "NUMERICAL_COLUMNS = ['accommodates', 'bathrooms', 'host_response_rate', 'number_of_reviews', 'review_scores_rating', 'bedrooms', 'beds']\n",
    "\n",
    "\n",
    "for col in IGNORE_COLUMNS:\n",
    "    try:\n",
    "        COLUMNS_TO_CHECK_CORRELATION.remove(col)\n",
    "    except ValueError:\n",
    "        pass  # do nothing!\n",
    "    \n",
    "print(COLUMNS_TO_CHECK_CORRELATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(df, column):\n",
    "    current_date = pd.to_datetime(\"today\")\n",
    "    df[column] = pd.to_datetime(df[column], errors='coerce')  # Coerce errors will turn problematic parsing into NaT\n",
    "    df[column + '_days_since'] = (current_date - df[column]).dt.days\n",
    "    df[column] = df[column + '_days_since']\n",
    "    \n",
    "def process_numerical(df, column):\n",
    "    if column == 'host_response_rate':\n",
    "        df[column] = df[column].str.replace('%', '')\n",
    "    df[column] = df[column].astype(float)\n",
    "    \n",
    "def process_categorical(df, column):\n",
    "    return pd.get_dummies(df[column], prefix=column)\n",
    "    \n",
    "def encode_df(X_columns, y_column):\n",
    "    df = original_df.copy()\n",
    "    all_columns = X_columns.copy()\n",
    "    all_columns.append(y_column)\n",
    "\n",
    "    df = df[all_columns].dropna(how='any')\n",
    "    y = df[[y_column]]\n",
    "    \n",
    "    processed_columns = []\n",
    "    for column in X_columns:\n",
    "        if column in CATEGORICAL_COLUMNS:\n",
    "            processed_columns.append(process_categorical(df, column))\n",
    "        elif column in DATE_COLUMNS:\n",
    "            process_date(df, column)\n",
    "            processed_columns.append(df[column])\n",
    "        elif column in NUMERICAL_COLUMNS:\n",
    "            process_numerical(df, column)\n",
    "            processed_columns.append(df[column])\n",
    "            \n",
    "    if y_column == \"host_has_profile_pic\":\n",
    "        y = df[y_column].replace({'t': 1, 'f': 0})\n",
    "    elif y_column == \"host_identity_verified\":\n",
    "        y = df[y_column].replace({'t': 1, 'f': 0})\n",
    "    elif y_column in DATE_COLUMNS:\n",
    "        process_date(df, y_column)\n",
    "        y = df[y_column]\n",
    "\n",
    "    processed_columns = pd.concat(processed_columns, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(processed_columns, y, test_size=0.2)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test.to_numpy().squeeze()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_MCAR(column_name, correlation_threshold=0.7, chi2p_threshold=0.05):\n",
    "    \n",
    "    interesting_columns = []\n",
    "    \n",
    "    df = original_df.copy()\n",
    "\n",
    "    for column in COLUMNS_TO_CHECK_CORRELATION:\n",
    "        if column == column_name:\n",
    "            continue\n",
    "        \n",
    "        # preprocess date\n",
    "        \n",
    "        if column in NUMERICAL_COLUMNS:\n",
    "            \n",
    "            process_numerical(df, column)\n",
    "            correlation = df[column].corr(df[column_name].isnull(), method='pearson')\n",
    "\n",
    "            # print(\"Correlation between '{}' and '{}':\".format(column, column_name))\n",
    "            # print(correlation)\n",
    "            \n",
    "            if abs(correlation) > correlation_threshold:\n",
    "                interesting_columns.append(column)\n",
    "        \n",
    "        if column in DATE_COLUMNS:\n",
    "            process_date(df, column)\n",
    "            \n",
    "            correlation = df[column].corr(df[column_name].isnull(), method='pearson')\n",
    "            \n",
    "            # print(\"Correlation between '{}' and '{}':\".format(column, column_name))\n",
    "            # print(correlation)\n",
    "            \n",
    "            if abs(correlation) > correlation_threshold:\n",
    "                interesting_columns.append(column)\n",
    "            \n",
    "\n",
    "        if column in CATEGORICAL_COLUMNS:\n",
    "            contingency_table = pd.crosstab(index=df[column], columns=df[column_name].isnull())\n",
    "            chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "            \n",
    "            # print(\"Contingency correlation between '{}' and '{}':\".format(column, column_name))\n",
    "            # print(p)\n",
    "            \n",
    "            if abs(p) > chi2p_threshold:\n",
    "                interesting_columns.append(column)\n",
    "                \n",
    "                \n",
    "    print(f\"columns that are correlated with {column_name} as a missing column:\", interesting_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = date, categorical\n",
    "\n",
    "# numerical, numerical -> corr\n",
    "# categorical, categorical -> chi2\n",
    "# numerical, categorical -> foneway (anova)\n",
    "\n",
    "def is_numerical(column_name):\n",
    "    return column_name in NUMERICAL_COLUMNS or column_name in DATE_COLUMNS\n",
    "\n",
    "def is_MAR(column_name, correlation_threshold=0.7, chi2p_threshold=0.05, anovap_threshold=0.05):\n",
    "    \n",
    "    interesting_columns = []\n",
    "    \n",
    "    df = original_df.copy()\n",
    "    \n",
    "    if column_name in DATE_COLUMNS:  \n",
    "        process_date(df, column_name)\n",
    "    elif column_name in NUMERICAL_COLUMNS:\n",
    "        process_numerical(df, column_name)\n",
    "    \n",
    "\n",
    "    for column in COLUMNS_TO_CHECK_CORRELATION:\n",
    "        if column == column_name:\n",
    "            continue\n",
    "        \n",
    "        if column in DATE_COLUMNS:  \n",
    "            process_date(df, column)\n",
    "        elif column in NUMERICAL_COLUMNS:\n",
    "            process_numerical(df, column)\n",
    "            \n",
    "        two_column_df = df[[column, column_name]].dropna()\n",
    "        \n",
    "        if is_numerical(column) and is_numerical(column_name):\n",
    "            \n",
    "            correlation = two_column_df[column].corr(two_column_df[column_name], method='pearson')\n",
    "\n",
    "            # print(\"Correlation between '{}' and '{}':\".format(column, column_name))\n",
    "            # print(correlation)\n",
    "            \n",
    "            if abs(correlation) > correlation_threshold:\n",
    "                interesting_columns.append(column)\n",
    "                \n",
    "        elif column in CATEGORICAL_COLUMNS and column_name in CATEGORICAL_COLUMNS:\n",
    "            contingency_table = pd.crosstab(index=two_column_df[column], columns=two_column_df[column_name])\n",
    "            chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "            \n",
    "            # print(\"Contingency correlation between '{}' and '{}':\".format(column, column_name))\n",
    "            # print(contingency_table)\n",
    "            # print(p)\n",
    "            \n",
    "            if abs(p) > chi2p_threshold:\n",
    "                interesting_columns.append(column)\n",
    "            \n",
    "        elif (is_numerical(column) and column_name in CATEGORICAL_COLUMNS) or (is_numerical(column_name) and column in CATEGORICAL_COLUMNS):\n",
    "            \n",
    "            numerical_column = column if is_numerical(column) else column_name\n",
    "            categorical_column = column if (column in CATEGORICAL_COLUMNS) else column_name\n",
    "            \n",
    "            # le = LabelEncoder()\n",
    "            # two_column_df[categorical_column] = le.fit_transform(two_column_df[categorical_column])\n",
    "            \n",
    "            # corr, p_value = stats.pointbiserialr(two_column_df[categorical_column], two_column_df[numerical_column])\n",
    "                        \n",
    "            groups = two_column_df.groupby(categorical_column)\n",
    "\n",
    "            # Step 3: Perform ANOVA\n",
    "            f_statistic, p_value = f_oneway(*[group[numerical_column] for _, group in groups])\n",
    "            \n",
    "            if abs(p_value) < anovap_threshold:\n",
    "                interesting_columns.append(column)\n",
    "        \n",
    "                \n",
    "    print(f\"columns that are correlated with {column_name}\", interesting_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_numerical_y(X_train, X_test, y_train, y_test, num_clusters, k):\n",
    "    # linear reg\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('using linear reg', mean_squared_error(y_pred, y_test)) # MSE for numerical\n",
    "    \n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, (y_train * k).astype('int'))\n",
    "    y_pred = model.predict(X_test) / k\n",
    "\n",
    "    print('using logistic reg', mean_squared_error(y_pred, y_test)) # MSE for numerical\n",
    "    \n",
    "\n",
    "    # KNN\n",
    "    model = KNeighborsClassifier(n_neighbors=num_clusters)\n",
    "    \n",
    "    # model.fit(X_train, y_train).astype('int')\n",
    "    # y_pred = model.predict(X_test)\n",
    "    \n",
    "    model.fit(X_train, (y_train * k).astype('int'))\n",
    "    y_pred = model.predict(X_test) / k\n",
    "\n",
    "    print('using knn', mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "    # randomforest\n",
    "    model = RandomForestClassifier()\n",
    "    \n",
    "    # model.fit(X_train, y_train).astype('int')\n",
    "    # y_pred = model.predict(X_test)\n",
    "    \n",
    "    model.fit(X_train, (y_train * k).astype('int'))\n",
    "    y_pred = model.predict(X_test) / k\n",
    "\n",
    "    print('using random forest', mean_squared_error(y_pred, y_test))\n",
    "\n",
    "\n",
    "    # mean\n",
    "    mean_value = y_train.mean()\n",
    "    print('using mean', mean_squared_error(np.full(len(y_test), mean_value), y_test))\n",
    "\n",
    "    # median\n",
    "    mean_value = y_train.median()\n",
    "    print('using median', mean_squared_error(np.full(len(y_test), mean_value), y_test))\n",
    "\n",
    "    # mode\n",
    "    mode_value = y_train.mode()\n",
    "    print('using mode', mean_squared_error(np.full(len(y_test), mode_value), y_test))\n",
    "    \n",
    "    \n",
    "def train_mcar(column_name):\n",
    "    \n",
    "    df = original_df.copy()\n",
    "\n",
    "    if column_name in DATE_COLUMNS:  \n",
    "        process_date(df, column_name)\n",
    "    elif column_name in NUMERICAL_COLUMNS:\n",
    "        process_numerical(df, column_name)\n",
    "        \n",
    "    y = df[column_name].copy().dropna().to_numpy().squeeze()\n",
    "    \n",
    "    y_train = y[:int(len(y) * 0.8)]\n",
    "    y_test = y[int(len(y) * 0.8):]\n",
    "    \n",
    "    # mean\n",
    "    mean_value = y_train.mean()\n",
    "    print('using mean', mean_squared_error(np.full(len(y_test), mean_value), y_test))\n",
    "\n",
    "    # median\n",
    "    mean_value = np.median(y_train)\n",
    "    print('using median', mean_squared_error(np.full(len(y_test), mean_value), y_test))\n",
    "\n",
    "    # mode\n",
    "    mode_value = mode(y_train)[0]\n",
    "    print('using mode', mean_squared_error(np.full(len(y_test), mode_value), y_test))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per column analysis - bathrooms/bedrooms/beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with bathrooms as a missing column: ['bed_type', 'host_has_profile_pic', 'host_identity_verified']\n",
      "columns that are correlated with bathrooms ['property_type', 'room_type', 'cancellation_policy']\n",
      "using linear reg 0.3038899240722871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using logistic reg 0.3986166542650342\n",
      "using knn 0.3986166542650342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/x0z_l9z95f984fpzdls50gmw0000gn/T/ipykernel_4984/817887534.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, (y_train * 2).astype('int'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using random forest 0.3953189474396266\n",
      "using mean 0.3445156785019402\n",
      "using median 0.4006460123114388\n",
      "using mode 0.4006460123114388\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - bathrooms\n",
    "\n",
    "# by domain knowledge, it should be related to 'property_type', 'room_type', 'accommodates', 'bedrooms'\n",
    "\n",
    "is_MCAR(\"bathrooms\") # has some correlated columns, meaning it is not MCAR, it is either MAR or MNAR\n",
    "\n",
    "is_MAR(\"bathrooms\", correlation_threshold=0.7, chi2p_threshold=0.05, anovap_threshold=1e-100) # is_corr\n",
    "\n",
    "X_columns = ['property_type', 'room_type']\n",
    "y_column = \"bathrooms\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, len(original_df[y_column].unique()), 2) # Linear regression has the lowest MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with bedrooms as a missing column: ['property_type', 'bed_type', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
      "columns that are correlated with bedrooms ['property_type', 'room_type', 'accommodates', 'bed_type', 'cancellation_policy', 'cleaning_fee', 'host_identity_verified', 'beds']\n",
      "using linear reg 0.3007885274376603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using logistic reg 0.32257846320346323\n",
      "using knn 0.339353354978355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/x0z_l9z95f984fpzdls50gmw0000gn/T/ipykernel_4984/817887534.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, (y_train * 2).astype('int'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using random forest 0.3040449134199134\n",
      "using mean 0.7233747116042945\n",
      "using median 0.7928841991341992\n",
      "using mode 0.7928841991341992\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - bedrooms\n",
    "\n",
    "is_MCAR(\"bedrooms\")\n",
    "\n",
    "is_MAR(\"bedrooms\")\n",
    "\n",
    "X_columns = ['property_type', 'room_type', 'accommodates', 'bed_type', 'beds']\n",
    "y_column = \"bedrooms\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, len(original_df[y_column].unique()), 2) # Linear regression has the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with beds as a missing column: ['property_type', 'bed_type', 'host_has_profile_pic', 'instant_bookable']\n",
      "columns that are correlated with beds ['property_type', 'room_type', 'accommodates', 'bed_type', 'cancellation_policy', 'cleaning_fee', 'host_identity_verified', 'instant_bookable', 'bedrooms']\n",
      "using linear reg 3.8017572631883366e+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using logistic reg 0.5586444805194806\n",
      "using knn 0.48856872294372294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/x0z_l9z95f984fpzdls50gmw0000gn/T/ipykernel_4984/817887534.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, (y_train * 2).astype('int'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using random forest 0.4933712121212121\n",
      "using mean 1.488282387821623\n",
      "using median 1.977813852813853\n",
      "using mode 1.977813852813853\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - beds\n",
    "\n",
    "is_MCAR(\"beds\")\n",
    "\n",
    "is_MAR(\"beds\")\n",
    "\n",
    "X_columns = ['property_type', 'room_type', 'accommodates', 'bed_type', 'bedrooms']\n",
    "y_column = \"beds\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, len(original_df[y_column].unique()), 2) # linear regression has the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with first_review as a missing column: []\n",
      "using mean 245738.65493215437\n",
      "using median 263282.69442060083\n",
      "using mode 370669.9900429185\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - first_review\n",
    "\n",
    "is_MCAR(\"first_review\") # MCAR\n",
    "\n",
    "train_mcar(\"first_review\") # use mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with last_review as a missing column: []\n",
      "using mean 53170.763559042054\n",
      "using median 54947.973749678305\n",
      "using mode 55120.88650596208\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - last_review\n",
    "\n",
    "is_MCAR(\"last_review\")  # MCAR\n",
    "\n",
    "train_mcar(\"last_review\")  # use mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with review_scores_rating as a missing column: []\n",
      "columns that are correlated with review_scores_rating ['property_type', 'room_type', 'cancellation_policy', 'cleaning_fee', 'host_identity_verified', 'instant_bookable']\n",
      "using linear reg 57.82099802383128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using logistic reg 93.05985363303711\n",
      "using knn 79.69245513155602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/x0z_l9z95f984fpzdls50gmw0000gn/T/ipykernel_4984/3344523772.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, (y_train * k).astype('int'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using random forest 92.8031015856421\n",
      "using mean 58.60268201741361\n",
      "using median 62.094528663530234\n",
      "using mode 93.05671719811814\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - review_scores_rating\n",
    "\n",
    "is_MCAR(\"review_scores_rating\")\n",
    "\n",
    "is_MAR(\"review_scores_rating\")\n",
    "\n",
    "X_columns = ['property_type', 'room_type', 'cleaning_fee', 'instant_bookable']\n",
    "y_column = \"review_scores_rating\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, 10, 100) # linear regression has the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with host_has_profile_pic as a missing column: ['bed_type', 'cancellation_policy', 'cleaning_fee', 'host_identity_verified', 'instant_bookable']\n",
      "columns that are correlated with host_has_profile_pic ['property_type', 'room_type', 'bed_type', 'first_review', 'host_response_rate', 'host_since', 'number_of_reviews']\n",
      "using linear reg 229169436281819.84\n",
      "using logistic reg 0.0031112614135948595\n",
      "using knn 0.02238755495434562\n",
      "using random forest 0.0031112614135948595\n",
      "using mean 0.0031015860267421726\n",
      "using median 0.0031112614135948595\n",
      "using mode 0.0031112614135948595\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - host_has_profile_pic\n",
    "\n",
    "is_MCAR(\"host_has_profile_pic\")\n",
    "\n",
    "is_MAR(\"host_has_profile_pic\")\n",
    "\n",
    "X_columns = ['property_type', 'room_type', 'cleaning_fee', 'instant_bookable']\n",
    "y_column = \"host_has_profile_pic\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, 2, 1) # abt the same but linear regression has the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with host_identity_verified as a missing column: ['bed_type', 'cancellation_policy', 'cleaning_fee', 'host_has_profile_pic', 'instant_bookable']\n",
      "columns that are correlated with host_identity_verified ['accommodates', 'bathrooms', 'first_review', 'host_response_rate', 'host_since', 'last_review', 'number_of_reviews', 'review_scores_rating', 'bedrooms', 'beds']\n",
      "using linear reg 0.17408303667099453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using logistic reg 0.23969449675664364\n",
      "using knn 0.36702238962125966\n",
      "using random forest 0.22421008579200669\n",
      "using mean 0.19394606005739892\n",
      "using median 0.2631303620004185\n",
      "using mode 0.2631303620004185\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - host_identity_verified\n",
    "\n",
    "is_MCAR(\"host_identity_verified\")\n",
    "\n",
    "is_MAR(\"host_identity_verified\")\n",
    "\n",
    "X_columns = ['accommodates', 'bathrooms', 'first_review', 'host_response_rate', 'host_since', 'number_of_reviews', 'review_scores_rating', 'bedrooms', 'beds']\n",
    "y_column = \"host_identity_verified\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, 2, 1) # linear regression has the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with host_response_rate as a missing column: []\n",
      "columns that are correlated with host_response_rate ['property_type', 'room_type', 'cancellation_policy', 'cleaning_fee', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
      "using mean 253.9039285575161\n",
      "using median 283.5200214995969\n",
      "using mode 283.5200214995969\n"
     ]
    }
   ],
   "source": [
    "# Per column analysis - host_response_rate\n",
    "\n",
    "is_MCAR(\"host_response_rate\")\n",
    "\n",
    "train_mcar(\"host_response_rate\")  # use mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that are correlated with host_since as a missing column: ['bed_type', 'cancellation_policy', 'cleaning_fee', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
      "columns that are correlated with host_since ['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'cleaning_fee', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
      "using linear reg 371163.9804024349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m y_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost_since\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m encode_df(X_columns, y_column)\n\u001b[0;32m---> 10\u001b[0m train_numerical_y(X_train, X_test, y_train, y_test, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[89], line 11\u001b[0m, in \u001b[0;36mtrain_numerical_y\u001b[0;34m(X_train, X_test, y_train, y_test, num_clusters, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musing linear reg\u001b[39m\u001b[38;5;124m'\u001b[39m, mean_squared_error(y_pred, y_test)) \u001b[38;5;66;03m# MSE for numerical\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m---> 11\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, (y_train \u001b[38;5;241m*\u001b[39m k)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;241m/\u001b[39m k\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musing logistic reg\u001b[39m\u001b[38;5;124m'\u001b[39m, mean_squared_error(y_pred, y_test)) \u001b[38;5;66;03m# MSE for numerical\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[1;32m   1292\u001b[0m     path_func(\n\u001b[1;32m   1293\u001b[0m         X,\n\u001b[1;32m   1294\u001b[0m         y,\n\u001b[1;32m   1295\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[1;32m   1296\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[1;32m   1297\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[1;32m   1298\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m   1299\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1300\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1301\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[1;32m   1302\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[1;32m   1303\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1304\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m   1305\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   1307\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[1;32m   1308\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[1;32m   1309\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   1310\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1311\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m   1312\u001b[0m     )\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[1;32m   1314\u001b[0m )\n\u001b[1;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    449\u001b[0m ]\n\u001b[0;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    451\u001b[0m     func,\n\u001b[1;32m    452\u001b[0m     w0,\n\u001b[1;32m    453\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    454\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    455\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[1;32m    456\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    459\u001b[0m     solver,\n\u001b[1;32m    460\u001b[0m     opt_res,\n\u001b[1;32m    461\u001b[0m     max_iter,\n\u001b[1;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    463\u001b[0m )\n\u001b[1;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:361\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    355\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:278\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[0;32m--> 278\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_loss\u001b[38;5;241m.\u001b[39mloss_gradient(\n\u001b[1;32m    279\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    280\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m    281\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    282\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    285\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/_loss/loss.py:200\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    191\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m ReadonlyArrayWrapper(sample_weight)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mloss(\n\u001b[1;32m    193\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[1;32m    194\u001b[0m         raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_gradient\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    202\u001b[0m     y_true,\n\u001b[1;32m    203\u001b[0m     raw_prediction,\n\u001b[1;32m    204\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m     loss_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    208\u001b[0m ):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m        Element-wise gradients.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Per column analysis - host_since\n",
    "\n",
    "is_MCAR(\"host_since\")\n",
    "is_MAR(\"host_since\")\n",
    "\n",
    "\n",
    "X_columns = ['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']\n",
    "y_column = \"host_since\"\n",
    "X_train, X_test, y_train, y_test = encode_df(X_columns, y_column)\n",
    "train_numerical_y(X_train, X_test, y_train, y_test, 10, 1) # linear regression has the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per column analysis - neighbourhood, zipcode\n",
    "\n",
    "\n",
    "print(original_df['neighbourhood'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
